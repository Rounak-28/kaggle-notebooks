# This code cell is to get rid of annoying tensorflow warnings
import os
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'


import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import tensorflow as tf


df_train = pd.read_csv("train.csv")
df_test = pd.read_csv("test.csv")


# np.array(df_train["alcohol"]).max()
df_train["fixed acidity"] = df_train["fixed acidity"] / 16
df_train["residual sugar"] = df_train["residual sugar"] / 16
df_train["free sulfur dioxide"] = df_train["free sulfur dioxide"] / 70
df_train["total sulfur dioxide"] = df_train["total sulfur dioxide"] / 300
df_train["pH"] = df_train["pH"] / 4
df_train["alcohol"] = df_train["alcohol"] / 14


df_test["fixed acidity"] = df_test["fixed acidity"] / 16
df_test["residual sugar"] = df_test["residual sugar"] / 16
df_test["free sulfur dioxide"] = df_test["free sulfur dioxide"] / 70
df_test["total sulfur dioxide"] = df_test["total sulfur dioxide"] / 300
df_test["pH"] = df_test["pH"] / 4
df_test["alcohol"] = df_test["alcohol"] / 14


df_train


y_train = df_train["quality"]


X_train = df_train.drop(["Id", "quality"],axis=1).to_numpy()
X_test = df_test.drop(["Id"],axis=1).to_numpy()


X_train


model = tf.keras.models.Sequential([
  tf.keras.layers.Flatten(),
  tf.keras.layers.Dense(256, activation='relu'),
  tf.keras.layers.Dropout(0.4),
  tf.keras.layers.Dense(128, activation='relu'),
  tf.keras.layers.Dropout(0.4),
  tf.keras.layers.Dense(9, activation='softmax')
])
# from sklearn.linear_model import LogisticRegression
# model1 = LogisticRegression(max_iter=10000)


model.compile(optimizer='AdaMax',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])



model.fit(X_train, y_train, epochs=50)
# model1.fit(X_train, y_train)


# ans1 = model1.predict(X_test)


ans = np.argmax(model.predict(X_test), 1)


ans


df_ans = pd.DataFrame({"Id": df_test["Id"], "quality": ans})
# df_ans1 = pd.DataFrame({"Id": df_test["Id"], "quality": ans1})


df_ans.to_csv("outputs/ans4.csv", index=False)



